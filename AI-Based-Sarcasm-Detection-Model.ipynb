{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6NTy5F42eU_1"
   },
   "source": [
    "This project closely follows [this tutorial.](https://towardsdatascience.com/sarcasm-detection-step-towards-sentiment-analysis-84cb013bb6db)\n",
    "\n",
    "**Introduction**\n",
    "\n",
    "\n",
    "With the advent and rise of social media, automated moderation becomes more and more necessary. However, the extent of moderation is always a sensitive issue and needs to be dealt with sensitively. \n",
    "\n",
    "Sentiment analysis can help with this, to some extent, but it more or less always fails to detect sarcasm – where a sentence may be worded negatively to express a positive emotion, or vice-versa. An auto-moderation system based simply on basic sentiment analysis may fail to recognise sarcasm and may increase the load of the human overseeing the system rather than decrease it. \n",
    "\n",
    "This program is, therefore, an attempt at identifying sarcasm in language – a small first step in what may be the development of a fully-fledged system that can handle moderation requests and make the Internet a safer and happier place for the world to interact with. \n",
    "\n",
    "\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "\n",
    "**1. Overview**\n",
    "\n",
    "- Problem Statement\n",
    "- Objective and Scope of the Project\n",
    "- Data Sources\n",
    "- Tools and Techniques\n",
    "- Analytics Approach\n",
    "- Limitations\n",
    "\n",
    "**2. Data Description and Preparation**\n",
    "\n",
    "- Data Management\n",
    "- Data Table\n",
    "- Data Quality\n",
    "- Data Preparations\n",
    "\n",
    "**3. Predictive Model Development**\n",
    "\n",
    "- Development of Regression Models \n",
    "- Validation\n",
    "- Conclusion\n",
    "- Recommendations\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1y_givFehuk_"
   },
   "source": [
    "**1. Overview**\n",
    "\n",
    "It is known that basic sentiment analysis based on recognising positive and negative words is not enough to correctly identify a statement as being positive or negative in nature. It is, therefore, incredibly important to also incorporate sarcasm detection in such a system. \n",
    "\n",
    "To be able to detect sarcasm in a statement, we can use headlines from The Onion – a sarcastic news source, and another legitimate one. In the data source used, the other, serious, headlines have been taken from The Huffington Post. \n",
    "\n",
    "Linear and Logistic Regression have been applied to the dataset after vectorising it to identify sarcasm. \n",
    "\n",
    "\n",
    "\n",
    "- **Problem Statement:**\n",
    "\n",
    "  It is a well-known problem that simple sentiment analysis systems will not be able to detect sarcasm. It is, therefore, imperative to include a sentiment analysis module with it to make it more complete. \n",
    "\n",
    "  Through this project, we aim to be able to identify sarcastic headlines from serious ones. This may be the first step in building a more complete sentiment analysis system. \n",
    "\n",
    "  Such a complete system may aid in various auto-moderation techniques, automated reply techniques, or even a complete chatbot capable of handling a specific domain-related task. \n",
    "\n",
    "\n",
    "\n",
    "- **Objective and Scope of the Project**\n",
    "\n",
    "  - Objective:<br>\n",
    "    - The primary objective of the study is to make a model capable of identifying sarcasm in statements. \n",
    "\n",
    "  - Scope:<br>\n",
    "    - The scope of the study covers news headlines, taken from The Onion and from The Huffington Post.\n",
    "    - The study’s focus is on finding which statements are more likely to be sarcastic based on the words they are comprised of. \n",
    "\n",
    "  - Out of Scope:<br>\n",
    "    - Simple sentiment analysis. \n",
    "    - In-depth sarcasm analysis capable of analysing all sorts of statements.\n",
    "    - Identifying fake news.\n",
    "    \n",
    "\n",
    "- **Data Source**\n",
    "  \n",
    "  The data for the project was obtained from Kaggle. This News Headlines Dataset for Sarcasm Detection is collected from The Onion website which aims at producing sarcastic versions of current events and The Huffington Post website which collects real news headlines.\n",
    "  \n",
    "  The columns of the dataset are:\n",
    "  1.\tarticle_link  - links to the news articles.\n",
    "  2.\theadline  - headlines of the news articles.\n",
    "  3.\tis_sarcastic - 0(for serious text) and 1(for sarcastic text).\n",
    "  \n",
    "\n",
    "- **Tools & Techniques**\n",
    "\n",
    "  We have used the following Analytical techniques / methodology for analyzing the Data :\n",
    "  1.\tTerm Frequency-Inverse Document Frequency (TF-IDF) Vectorisation of the data\n",
    "  2.\tLinear Regression\n",
    "  3.\tLogistic Regression\n",
    "  4.\tPlotting the various results together. \n",
    "  \n",
    "\n",
    "- **Analytics Approach**\n",
    "\n",
    "  The Analytical Approach will involve the following (not necessarily in the order) activities:\n",
    "  - Data extraction from Primary Data source\n",
    "  - Data quality check\n",
    "  - Data cleaning and data preparation\n",
    "  - Term Frequency-Inverse Data Frequency Vectorisation\n",
    "  - Study the variables for its relevance for the study\n",
    "  - Identifying X and y variables for regression.\n",
    "  - Division of data into train and test\n",
    "  - Model Development\n",
    "  - Final Model\n",
    "  - Checking and plotting the accuracy of the model\n",
    "  - Intervention Strategies and recommendations\n",
    "  \n",
    "\n",
    "- **Limitations**\n",
    "\n",
    "  There are few limitations that this study has w.r.t data and the methodology that can be used.\n",
    "\n",
    "  It is not possible to collect or to predict accurately if data is sarcastic automatically. Hence, we have to use data from a reliable source. One of the best known such sources is The Onion, known for its sarcastic headlines and news articles. Once we have that, we can collect headlines from another reputable news source to provide serious headlines. \n",
    "\n",
    "  We also cannot collect more sorts of sarcastic data, such as jokes, tweets, stories, and social media posts. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UxBqN7N6sOzJ"
   },
   "source": [
    "**2. Data Description and Preparation**\n",
    "\n",
    "- **Data Management**\n",
    "  \n",
    "  All the necessary modules and the data source are first imported into the work environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "PbV2Yr5xeS3W",
    "outputId": "13937628-7676-4ffa-d620-65571bc44997"
   },
   "outputs": [],
   "source": [
    "# Importing the necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kykRHkl1s8C3"
   },
   "outputs": [],
   "source": [
    "# Importing the dataset, and checking that it has been properly imported\n",
    "data = pd.read_json(\"Sarcasm_Headlines_Dataset.json\", lines = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EXa-8px8tNvX"
   },
   "source": [
    "- **Data Table**\n",
    "\n",
    "  The data imported is checked and presented in tabular form. \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "xLM7DF-SteND",
    "outputId": "234b5bff-436b-4269-e825-d7457f0159b3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  former versace store clerk sues over secret 'b...             0  \n",
       "1  the 'roseanne' revival catches up to our thorn...             0  \n",
       "2  mom starting to fear son's web series closest ...             1  \n",
       "3  boehner just wants wife to listen, not come up...             1  \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rYofRzFEtjTD"
   },
   "source": [
    "- **Data Quality**\n",
    "\n",
    "  The data imported has punctuation in the strings. This is detrimental to our analysis and must be removed before further work is done. \n",
    "  \n",
    "  \n",
    "  \n",
    "- **Data Preparation**\n",
    "\n",
    "  - Variables Transformation\n",
    "\n",
    "    1.\tThe re module for regular expressions in Python was used to remove all the punctuation from the sentences. \n",
    "    2.\tThe PorterStemmer module is used to convert all words in the headlines to a root word, so that different forms of the same word are not analysed twice. \n",
    "    3.\tTF-IDF Vectorisation to convert the words into meaningful numbers so regression techniques may be applied. \n",
    "\n",
    "  - Missing Values\n",
    "\n",
    "    1.\tNo specific missing value treatment was used\n",
    "    2.\tMissing values were checked for and removed before the project was started. \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "4eMacx-Z4Zcm",
    "outputId": "03f9b55d-2ac6-46cf-e61e-9be50b9cbd60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_link    0\n",
       "headline        0\n",
       "is_sarcastic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xea60d30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data['is_sarcastic'], label = \"Sarcastic vs. Serious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "YeJzlYQRumOv",
    "outputId": "905d958f-f12a-4215-e84a-24fb9c6659e0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret  b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the  roseanne  revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son s web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen  not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j k  rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  former versace store clerk sues over secret  b...             0  \n",
       "1  the  roseanne  revival catches up to our thorn...             0  \n",
       "2  mom starting to fear son s web series closest ...             1  \n",
       "3  boehner just wants wife to listen  not come up...             1  \n",
       "4  j k  rowling wishes snape happy birthday in th...             0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing punctuation and checking if the changes have taken\n",
    "data['headline'] = data['headline'].apply(lambda s : re.sub('[^a-zA-Z]', ' ', s))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "sVJTEsHUuywW",
    "outputId": "90420fd6-120a-4875-d168-d426e1721466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      "0        former versace store clerk sues over secret  b...\n",
      "1        the  roseanne  revival catches up to our thorn...\n",
      "2        mom starting to fear son s web series closest ...\n",
      "3        boehner just wants wife to listen  not come up...\n",
      "4        j k  rowling wishes snape happy birthday in th...\n",
      "5                              advancing the world s women\n",
      "6           the fascinating case for eating lab grown meat\n",
      "7        this ceo will send your kids to school  if you...\n",
      "8        top snake handler leaves sinking huckabee camp...\n",
      "9        friday s morning email  inside trump s presser...\n",
      "10       airline passengers tackle man who rushes cockp...\n",
      "11       facebook reportedly working on healthcare feat...\n",
      "12       north korea praises trump and urges us voters ...\n",
      "13       actually  cnn s jeffrey lord has been  indefen...\n",
      "14       barcelona holds huge protest in support of ref...\n",
      "15       nuclear bomb detonates during rehearsal for  s...\n",
      "16       cosby lawyer asks why accusers didn t come for...\n",
      "17       stock analysts confused  frightened by boar ma...\n",
      "18       bloomberg s program to build better cities jus...\n",
      "19                                    craig hicks indicted\n",
      "20       courtroom sketch artist has clear manga influe...\n",
      "21       trump assures nation that decision for syrian ...\n",
      "22       qatar deporting dutch woman who reported she w...\n",
      "23              this is why you shouldn t go to the circus\n",
      "24       ted cruz hits the panic button   we could lose...\n",
      "25                   why writers must plan to be surprised\n",
      "26       obama visits arlington national cemetery to ho...\n",
      "27                                  ex con back behind bar\n",
      "28       after careful consideration  bush recommends o...\n",
      "29                remembrance is the beginning of the task\n",
      "                               ...                        \n",
      "26679    un opcw report blames syria government  islami...\n",
      "26680    kim jong un s absence leaves north korean gove...\n",
      "26681    dog born with odds stacked against her found j...\n",
      "26682    american dream week a smashing  mostly uninves...\n",
      "26683    complete idiot forgot to shave area between mo...\n",
      "26684    retreating clinton campaign torches iowa town ...\n",
      "26685       don t nobody wanna hear area man run his mouth\n",
      "26686       syrian civilians massacred during claire da...\n",
      "26687    readin  researchin  writin  and the tools to m...\n",
      "26688    report  uttering phrase  easy does it  prevent...\n",
      "26689    ted cruz blasts new york times for keeping boo...\n",
      "26690    voting underway in myanmar s first free electi...\n",
      "26691    ice cube thrown into sink flies up side like s...\n",
      "26692               fisherman s worst nightmare comes true\n",
      "26693    new bailiff tired of hearing how old bailiff d...\n",
      "26694    breaking   the onion  in kill range of boston ...\n",
      "26695    seaworld crowd applauds for dolphin playfully ...\n",
      "26696    zimbabwe s youth defy blackout to organize pro...\n",
      "26697    emma gonzalez   one of the biggest threats  to...\n",
      "26698    hackers breached u s  election agency after vo...\n",
      "26699    what you should buy your  basic  friend  accor...\n",
      "26700    what s in your mailbox  tips on what to do whe...\n",
      "26701             paul ryan is more of a con man than ever\n",
      "26702    pentagon to withhold budget figures out of res...\n",
      "26703    pope francis wearing sweater vestments he got ...\n",
      "26704                 american politics in moral free fall\n",
      "26705                              america s best    hikes\n",
      "26706                                reparations and obama\n",
      "26707    israeli ban targeting boycott supporters raise...\n",
      "26708                    gourmet gifts for the foodie     \n",
      "Name: headline, Length: 26709, dtype: object\n",
      "\n",
      "Labels\n",
      "0        0\n",
      "1        0\n",
      "2        1\n",
      "3        1\n",
      "4        0\n",
      "5        0\n",
      "6        0\n",
      "7        0\n",
      "8        1\n",
      "9        0\n",
      "10       0\n",
      "11       0\n",
      "12       0\n",
      "13       0\n",
      "14       0\n",
      "15       1\n",
      "16       1\n",
      "17       1\n",
      "18       0\n",
      "19       0\n",
      "20       1\n",
      "21       1\n",
      "22       0\n",
      "23       0\n",
      "24       0\n",
      "25       0\n",
      "26       0\n",
      "27       1\n",
      "28       1\n",
      "29       0\n",
      "        ..\n",
      "26679    0\n",
      "26680    1\n",
      "26681    0\n",
      "26682    0\n",
      "26683    1\n",
      "26684    1\n",
      "26685    1\n",
      "26686    1\n",
      "26687    0\n",
      "26688    1\n",
      "26689    0\n",
      "26690    0\n",
      "26691    1\n",
      "26692    0\n",
      "26693    1\n",
      "26694    1\n",
      "26695    1\n",
      "26696    0\n",
      "26697    0\n",
      "26698    0\n",
      "26699    0\n",
      "26700    0\n",
      "26701    0\n",
      "26702    1\n",
      "26703    1\n",
      "26704    0\n",
      "26705    0\n",
      "26706    0\n",
      "26707    0\n",
      "26708    0\n",
      "Name: is_sarcastic, Length: 26709, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identifying independent and dependent variables\n",
    "features = data['headline'] # Independent\n",
    "labels = data['is_sarcastic'] # Dependent\n",
    "print(\"Features:\")\n",
    "print(features)\n",
    "print()\n",
    "print(\"Labels\")\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "colab_type": "code",
    "id": "h2U9GnKIvPlC",
    "outputId": "c42e84f0-9639-4ecf-8c74-ee7c728038d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        former versac store clerk sue over secret blac...\n",
       "1        the roseann reviv catch up to our thorni polit...\n",
       "2        mom start to fear son s web seri closest thing...\n",
       "3        boehner just want wife to listen not come up w...\n",
       "4        j k rowl wish snape happi birthday in the most...\n",
       "5                                 advanc the world s women\n",
       "6                   the fascin case for eat lab grown meat\n",
       "7        thi ceo will send your kid to school if you wo...\n",
       "8             top snake handler leav sink huckabe campaign\n",
       "9        friday s morn email insid trump s presser for ...\n",
       "10       airlin passeng tackl man who rush cockpit in b...\n",
       "11       facebook reportedli work on healthcar featur a...\n",
       "12       north korea prais trump and urg us voter to re...\n",
       "13       actual cnn s jeffrey lord ha been indefens for...\n",
       "14        barcelona hold huge protest in support of refuge\n",
       "15       nuclear bomb deton dure rehears for spider man...\n",
       "16       cosbi lawyer ask whi accus didn t come forward...\n",
       "17            stock analyst confus frighten by boar market\n",
       "18       bloomberg s program to build better citi just ...\n",
       "19                                       craig hick indict\n",
       "20         courtroom sketch artist ha clear manga influenc\n",
       "21       trump assur nation that decis for syrian airst...\n",
       "22       qatar deport dutch woman who report she wa dru...\n",
       "23                thi is whi you shouldn t go to the circu\n",
       "24       ted cruz hit the panic button we could lose bo...\n",
       "25                      whi writer must plan to be surpris\n",
       "26       obama visit arlington nation cemeteri to honor...\n",
       "27                                  ex con back behind bar\n",
       "28            after care consider bush recommend oil drill\n",
       "29                        remembr is the begin of the task\n",
       "                               ...                        \n",
       "26679    un opcw report blame syria govern islam state ...\n",
       "26680    kim jong un s absenc leav north korean govern ...\n",
       "26681    dog born with odd stack against her found just...\n",
       "26682    american dream week a smash mostli uninvestig ...\n",
       "26683    complet idiot forgot to shave area between mou...\n",
       "26684    retreat clinton campaign torch iowa town to sl...\n",
       "26685        don t nobodi wanna hear area man run hi mouth\n",
       "26686    syrian civilian massacr dure clair dane emmi a...\n",
       "26687    readin researchin writin and the tool to make ...\n",
       "26688    report utter phrase easi doe it prevent of dry...\n",
       "26689    ted cruz blast new york time for keep book off...\n",
       "26690    vote underway in myanmar s first free elect in...\n",
       "26691    ice cube thrown into sink fli up side like ska...\n",
       "26692                 fisherman s worst nightmar come true\n",
       "26693    new bailiff tire of hear how old bailiff did t...\n",
       "26694    break the onion in kill rang of boston bomber ...\n",
       "26695    seaworld crowd applaud for dolphin play spray ...\n",
       "26696    zimbabw s youth defi blackout to organ protest...\n",
       "26697    emma gonzalez one of the biggest threat to tee...\n",
       "26698    hacker breach u s elect agenc after vote accor...\n",
       "26699    what you should buy your basic friend accord t...\n",
       "26700    what s in your mailbox tip on what to do when ...\n",
       "26701             paul ryan is more of a con man than ever\n",
       "26702    pentagon to withhold budget figur out of respe...\n",
       "26703    pope franci wear sweater vestment he got for c...\n",
       "26704                    american polit in moral free fall\n",
       "26705                                  america s best hike\n",
       "26706                                      repar and obama\n",
       "26707    isra ban target boycott support rais alarm abroad\n",
       "26708                           gourmet gift for the foodi\n",
       "Name: headline, Length: 26709, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting all the words to the corresponding root word\n",
    "ps = PorterStemmer()\n",
    "features = features.apply(lambda x: x.split())\n",
    "features = features.apply(lambda x : \" \".join([ps.stem(word) for word in x]))\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "8j9TGzUWvZW1",
    "outputId": "6ae02257-9c82-46be-e32a-3f52289f71ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing TF-IDF Vectorisation on the features\n",
    "tv = TfidfVectorizer(max_features = 5000)\n",
    "features = list(features)\n",
    "features = tv.fit_transform(features).toarray()\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KJi1kiExyiWd"
   },
   "source": [
    "**3. Predictive Model Development**\n",
    "\n",
    " The headline statements were extracted as the “features” or the independent variables, and the values for whether or not the headline is sarcastic were extracted as the “labels” or the dependent variables.\n",
    " \n",
    "Then, various classification techniques were applied and their efficiencies found out. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0K-sKYrDvpWJ"
   },
   "outputs": [],
   "source": [
    "# Splitting into training and testing subsets\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = .05, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "lIPu85t7vv2d",
    "outputId": "55e4b584-4533-457b-fcaa-625c08350559"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing Logistic Regression and printing scores\n",
    "logr = LogisticRegression(solver='lbfgs')\n",
    "logr.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "colab_type": "code",
    "id": "tp8_E3fBztp-",
    "outputId": "2acb821d-fb5e-47aa-ec04-5cd567d99f3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85       746\n",
      "           1       0.82      0.80      0.81       590\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1336\n",
      "   macro avg       0.83      0.83      0.83      1336\n",
      "weighted avg       0.83      0.83      0.83      1336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking classification report for Logistic Regression\n",
    "labels_pred = logr.predict(features_test)\n",
    "print(classification_report(labels_test, labels_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o10mqfBY11Xz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing Decision Tree Classification\n",
    "dtree = DecisionTreeClassifier(criterion = 'entropy')\n",
    "dtree.fit(features_train,labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LG-O0LmF22uC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77       746\n",
      "           1       0.71      0.71      0.71       590\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      1336\n",
      "   macro avg       0.74      0.74      0.74      1336\n",
      "weighted avg       0.74      0.74      0.74      1336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking classification report for Decision Tree\n",
    "labels_pred = dtree.predict(features_test)\n",
    "print(classification_report(labels_test, labels_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lV-U04pC3Gv7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing Random Forest Classification\n",
    "randomforest = RandomForestClassifier(n_estimators=150)\n",
    "randomforest.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BNK-8mQj4E0u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84       746\n",
      "           1       0.79      0.81      0.80       590\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1336\n",
      "   macro avg       0.82      0.82      0.82      1336\n",
      "weighted avg       0.82      0.82      0.82      1336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking classification report for Random Forest Classifier\n",
    "labels_pred = randomforest.predict(features_test)\n",
    "print(classification_report(labels_test, labels_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing Naive Bayes classification\n",
    "naivebayes = GaussianNB()\n",
    "naivebayes.fit(features_train,labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.66      0.74       746\n",
      "           1       0.66      0.83      0.74       590\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      1336\n",
      "   macro avg       0.75      0.75      0.74      1336\n",
      "weighted avg       0.76      0.74      0.74      1336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking classification report for Naive Bayes\n",
    "labels_pred = naivebayes.predict(features_test)\n",
    "print(classification_report(labels_test, labels_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing Linear Support Vector Classification\n",
    "lsvc = LinearSVC()\n",
    "lsvc.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86       746\n",
      "           1       0.82      0.81      0.82       590\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      1336\n",
      "   macro avg       0.84      0.83      0.84      1336\n",
      "weighted avg       0.84      0.84      0.84      1336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking classification report for Linear Support Vector Classification\n",
    "labels_pred = lsvc.predict(features_test)\n",
    "print(classification_report(labels_test, labels_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the classification is done best by Logistic Regression and LSVC, we can now write the code to take a headline as input and predict whether it is sarcastic or not. \n",
    "\n",
    "Some sample statements to test out: \n",
    " - 10,000+ migrants displaced in India amid COVID-19 lockdown \n",
    " - Camera operator with unusual name noticed in credits for third episode in row\n",
    " - Child enchanted by bidet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a headline to be checked for sarcasm: Camera operator with unusual name noticed in credits for third episode in row\n",
      "Sarcastic.\n"
     ]
    }
   ],
   "source": [
    "X = input(\"Enter a headline to be checked for sarcasm: \")\n",
    "X = re.sub('[^a-zA-Z]', ' ', X)\n",
    "X = \" \".join([ps.stem(i) for i in X.lower().split()])\n",
    "X = tv.transform([X]).toarray()\n",
    "\n",
    "def predict(text):\n",
    "    return \"Sarcastic.\" if logr.predict(text)[0] == 1 else \"Serious.\"\n",
    "\n",
    "print(predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sarcastic.\n"
     ]
    }
   ],
   "source": [
    "def predict2(text):\n",
    "    return \"Sarcastic.\" if lsvc.predict(text)[0] == 1 else \"Serious.\"\n",
    "\n",
    "print(predict2(X))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
